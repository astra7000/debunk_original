# í”¼ë¶€ ë¶„ì„ AI ëª¨ë¸ ê°œë°œ ë° ì„±ëŠ¥ ê°œì„  í”„ë¡œì íŠ¸

## 1. í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ í”„ë¡œì íŠ¸ëŠ” ê° í”¼ë¶€ ì˜ì—­ì— ë”°ë¥´ëŠ” í”¼ë¶€ ìƒíƒœë¥¼ ëª‡ê°œì˜ í´ë˜ìŠ¤(ë¶„ë¥˜í•˜ê³ ì í•˜ëŠ” ì–¼êµ´ ì˜ì—­ê³¼ ë¶„ë¥˜ ëª©ì ì— ë”°ë¼ í´ë˜ìŠ¤ ìˆ˜ê°€ ë‹¤ë¦„)ë¡œ ë¶„ë¥˜í•˜ëŠ” ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨.

í”„ë¡œì íŠ¸ì˜ ê°€ì¥ í° ê¸°ìˆ ì  ê³¼ì œëŠ” **ì‹¬ê°í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•(Class Imbalance)** ë¬¸ì œì„. ì˜ˆì‹œë¡œ, ì´ë§ˆ ì£¼ë¦„ ë°ì´í„°ì…‹ì—ì„œ 2ë²ˆ í´ë˜ìŠ¤ì˜ ì´ë¯¸ì§€ ìˆ˜ëŠ” 5,000ê°œê°€ ë„˜ëŠ” ë°˜ë©´, 0ë²ˆ í´ë˜ìŠ¤ëŠ” 600ê°œ ë¯¸ë§Œìœ¼ë¡œ ì¡´ì¬í•˜ì—¬ ëª¨ë¸ì´ ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ ì œëŒ€ë¡œ í•™ìŠµí•˜ì§€ ëª»í•˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•¨.

ì˜ˆì‹œ ë¶„í¬(ì´ë§ˆ ì£¼ë¦„ ë°ì´í„°):
```
í´ë˜ìŠ¤ ìˆ˜: 7
í´ë˜ìŠ¤ ëª©ë¡: 0, 1, 2, 3, 4, 5, 6
í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:
  0: 572ê°œ
  1: 5083ê°œ
  2: 3393ê°œ
  3: 2340ê°œ
  4: 1092ê°œ
  5: 819ê°œ
  6: 637ê°œ
```

ì´ ë¬¸ì„œëŠ” ì´ˆê¸° ëª¨ë¸ì˜ ë¬¸ì œì ì„ ì§„ë‹¨í•˜ê³ , ë‹¤ì–‘í•œ í•´ê²°ì±…ì„ ë…¼ì˜í•˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ì½”ë“œì™€ í•™ìˆ ì  ê·¼ê±°ì— ê¸°ë°˜í•œ ìµœì ì˜ ì†”ë£¨ì…˜ì„ ë„ì¶œí•´ë‚˜ê°€ëŠ” ê³¼ì •ì„ ê¸°ë¡í•¨.

---

## 2. í•µì‹¬ ê¸°ìˆ  ë° ê°œë…

- **Backbone Model**: `ResNet-50`
- **Key Challenge**: ì‹¬ê°í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°ì´í„°ì…‹
- **Solutions Discussed**:
  - **Loss-Level Approach**:
    - `Class-Balanced Loss` (CB Loss)[1]
    - `Focal Loss`[2]
  - **Data-Level Approach**:
    - `Data Augmentation` (Oversampling)
  - **Optimization**:
    - `wandb.sweeps`ë¥¼ ì´ìš©í•œ learning rate, drop out, weight decay, gamma, betaì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

---

## 2-1. Backbone Modelë¡œ ResNet-50 ì„ íƒ

### ResNet-50ì˜ í•µì‹¬ ê°œë…
**ResNet (Residual Network)**ëŠ” 2015ë…„ ImageNet ëŒ€íšŒì—ì„œ ìš°ìŠ¹í•œ ë”¥ëŸ¬ë‹ ì•„í‚¤í…ì²˜ë¡œ, **ì”ì°¨ ì—°ê²°(Residual Connection)**ì„ í†µí•´ 50ê°œ ë ˆì´ì–´ì˜ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ì—ì„œë„ ì•ˆì •ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### ResNet-50ì˜ êµ¬ì¡°ì  íŠ¹ì§•
- **4ê°œ ë¸”ë¡**: ê°ê° 64, 128, 256, 512 ì±„ë„ì˜ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
- **ì”ì°¨ ì—°ê²°**: ê° ë¸”ë¡ ë‚´ì—ì„œ ì…ë ¥ì„ ì¶œë ¥ì— ì§ì ‘ ë”í•˜ëŠ” skip connection
- **ë°°ì¹˜ ì •ê·œí™”**: ê° ì»¨ë³¼ë£¨ì…˜ í›„ ë°°ì¹˜ ì •ê·œí™”ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ
- **ê¸€ë¡œë²Œ í‰ê·  í’€ë§**: ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ ê³µê°„ ì°¨ì›ì„ í‰ê· í™”í•˜ì—¬ ê³¼ì í•© ë°©ì§€

### í”¼ë¶€ ì´ë¯¸ì§€ ë¶„ë¥˜ì— ResNet-50ì„ ì„ íƒí•œ ì´ìœ 
1. **ë†’ì€ í‘œí˜„ë ¥**: ë³µì¡í•œ í”¼ë¶€ ì§ˆí™˜ì˜ ë¯¸ì„¸í•œ íŠ¹ì§•(ìƒ‰ìƒ, ì§ˆê°, í˜•íƒœ ë“±)ì„ í¬ì°©í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ëª¨ë¸ ìš©ëŸ‰
2. **ì•ˆì •ì ì¸ í•™ìŠµ**: ì”ì°¨ ì—°ê²°ë¡œ ì¸í•´ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œì‹¤ ë¬¸ì œ ì—†ì´ ê¹Šì€ ë„¤íŠ¸ì›Œí¬ í•™ìŠµ ê°€ëŠ¥
3. **ì „ì´í•™ìŠµ íš¨ê³¼**: ImageNetì—ì„œ ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ë¥¼ í™œìš©í•˜ì—¬ ë¹ ë¥¸ ìˆ˜ë ´ê³¼ ë†’ì€ ì„±ëŠ¥ ë‹¬ì„±
4. **í´ë˜ìŠ¤ ë¶ˆê· í˜• ëŒ€ì‘**: ì•ˆì •ì ì¸ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ìœ¼ë¡œ ì†Œìˆ˜ í´ë˜ìŠ¤ë„ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥
5. **ğŸš€ ê²€ì¦ëœ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥**: 
   - **ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ë¥˜ì˜ í‘œì¤€**: ìˆ˜ë§ì€ ì˜ë£Œ AI ì—°êµ¬ì—ì„œ ResNet-50ì´ ê¸°ë³¸ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©ë˜ë©°, í”¼ë¶€ ì§ˆí™˜ ë¶„ë¥˜ì—ì„œë„ ê²€ì¦ëœ ì„±ëŠ¥ì„ ë³´ì„
   - **ì‹¤ì „ ê²€ì¦**: ì‹¤ì œ ì˜ë£Œ í™˜ê²½ì—ì„œì˜ ë°°í¬ ì‚¬ë¡€ê°€ í’ë¶€í•˜ì—¬ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„±ì´ ì…ì¦ë¨
   - **ì—°êµ¬ ìƒíƒœê³„**: ResNet-50 ê¸°ë°˜ì˜ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ë¥˜ ë…¼ë¬¸ì´ ìˆ˜ì²œ í¸ ë°œí‘œë˜ì–´, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ ìµœì í™” ì „ëµì´ ì˜ ì •ë¦½ë¨
   - **í´ë˜ìŠ¤ ë¶ˆê· í˜• ê·¹ë³µ**: ì˜ë£Œ ë°ì´í„°ì˜ íŠ¹ì„±ìƒ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ì‹¬í•œë°, ResNet-50ì€ ì´ëŸ¬í•œ ìƒí™©ì—ì„œë„ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ì…ì¦ë¨


## 2-2. ì†ì‹¤í•¨ìˆ˜(loss function) ì„ íƒ

### í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œì™€ ì†ì‹¤í•¨ìˆ˜ì˜ ì—­í• 
í´ë˜ìŠ¤ ë¶ˆê· í˜• ë°ì´í„°ì…‹ì—ì„œëŠ” ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë˜ì–´ í•™ìŠµë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ë°ì´í„°ì˜ ì–‘ì  ë¶ˆê· í˜•ë¿ë§Œ ì•„ë‹ˆë¼, ì†ì‹¤í•¨ìˆ˜ê°€ ê° í´ë˜ìŠ¤ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ê³ ë ¤í•œ ì†ì‹¤í•¨ìˆ˜ ì„ íƒì´ ëª¨ë¸ ì„±ëŠ¥ì— ê²°ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

### 1. Cross Entropy Loss (ê¸°ë³¸ ì†ì‹¤í•¨ìˆ˜)

#### íŠ¹ì§•
- **ì›ë¦¬**: ê° í´ë˜ìŠ¤ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ë¼ë²¨ ê°„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°
- **ìˆ˜ì‹**: `CE = -log(p_t)` (p_tëŠ” ì •ë‹µ í´ë˜ìŠ¤ì˜ ì˜ˆì¸¡ í™•ë¥ )
- **ì¥ì **: êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì´ë©°, ì¼ë°˜ì ì¸ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì¢‹ì€ ì„±ëŠ¥
- **ë‹¨ì **: í´ë˜ìŠ¤ ë¶ˆê· í˜• ìƒí™©ì—ì„œ ë‹¤ìˆ˜ í´ë˜ìŠ¤ì— í¸í–¥ë˜ì–´ í•™ìŠµ

#### í´ë˜ìŠ¤ ë¶ˆê· í˜•ì—ì„œì˜ ë¬¸ì œì 
```python
# ì˜ˆì‹œ: í´ë˜ìŠ¤ ë¶„í¬ê°€ {0: 9000, 1: 100}ì¸ ê²½ìš°
# ëª¨ë¸ì´ ëª¨ë“  ìƒ˜í”Œì„ í´ë˜ìŠ¤ 0ìœ¼ë¡œ ì˜ˆì¸¡í•´ë„ 90% ì •í™•ë„ ë‹¬ì„±
# í´ë˜ìŠ¤ 1ì€ ê±°ì˜ í•™ìŠµë˜ì§€ ì•ŠìŒ
```

### 2. Focal Loss

#### íŠ¹ì§•
- **ì›ë¦¬**: ì‰¬ìš´ ìƒ˜í”Œ(ë†’ì€ í™•ë¥ ë¡œ ë§ì¶”ëŠ” ìƒ˜í”Œ)ì˜ ì†ì‹¤ì„ ì¤„ì´ê³ , ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘
- **ìˆ˜ì‹**: `FL = -(1-p_t)^Î³ * log(p_t)` (Î³ëŠ” focusing parameter)
- **í•µì‹¬ ì•„ì´ë””ì–´**: Î³ ê°’ì´ í´ìˆ˜ë¡ ì–´ë ¤ìš´ ìƒ˜í”Œì— ë” ì§‘ì¤‘
- **ì¥ì **: ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„± í–¥ìƒ
- **ë‹¨ì **: í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ì°¨ì´ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ê³ ë ¤í•˜ì§€ ì•ŠìŒ

#### Focal Lossì˜ í•œê³„
- í´ë˜ìŠ¤ ë¶ˆê· í˜•ì˜ **ê·¼ë³¸ ì›ì¸**(ìƒ˜í”Œ ìˆ˜ ì°¨ì´)ì„ í•´ê²°í•˜ì§€ ëª»í•¨
- ì–´ë ¤ìš´ ìƒ˜í”Œì— ì§‘ì¤‘í•˜ì§€ë§Œ, ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ **í•™ìŠµ ê¸°íšŒ ë¶€ì¡±** ë¬¸ì œëŠ” ì—¬ì „íˆ ì¡´ì¬

### 3. Class-Balanced Loss (CB Loss)

#### íŠ¹ì§•
- **ì›ë¦¬**: ê° í´ë˜ìŠ¤ì˜ **ìœ íš¨ ìƒ˜í”Œ ìˆ˜(Effective Number)**ë¥¼ ê³„ì‚°í•˜ì—¬ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •
- **ìˆ˜ì‹**: `CB = (1-Î²^n_i)/(1-Î²) * CE` (n_iëŠ” í´ë˜ìŠ¤ iì˜ ìƒ˜í”Œ ìˆ˜, Î²ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°)
- **í•µì‹¬ ì•„ì´ë””ì–´**: ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ í´ë˜ìŠ¤ì¼ìˆ˜ë¡ ë” í° ê°€ì¤‘ì¹˜ ë¶€ì—¬
- **ì¥ì **: í´ë˜ìŠ¤ ë¶ˆê· í˜•ì˜ ê·¼ë³¸ ì›ì¸ì„ ì§ì ‘ì ìœ¼ë¡œ í•´ê²°

#### CB Lossì˜ ì‘ë™ ì›ë¦¬
```python
# ì˜ˆì‹œ: í´ë˜ìŠ¤ ë¶„í¬ê°€ {0: 9000, 1: 100}ì¸ ê²½ìš°
# í´ë˜ìŠ¤ 0ì˜ ê°€ì¤‘ì¹˜: ë‚®ìŒ (ë‹¤ìˆ˜ í´ë˜ìŠ¤)
# í´ë˜ìŠ¤ 1ì˜ ê°€ì¤‘ì¹˜: ë†’ìŒ (ì†Œìˆ˜ í´ë˜ìŠ¤)
# ê²°ê³¼: ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ í‹€ë ¸ì„ ë•Œ ë” í° íŒ¨ë„í‹° ë¶€ì—¬
```

### 4. CB Loss ì„ íƒ ì´ìœ 

#### 1. **í´ë˜ìŠ¤ ë¶ˆê· í˜•ì˜ ê·¼ë³¸ì  í•´ê²°**
- CB LossëŠ” í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ì°¨ì´ë¥¼ **ìˆ˜í•™ì ìœ¼ë¡œ ì •ëŸ‰í™”**í•˜ì—¬ í•´ê²°
- ë‹¨ìˆœí•œ ê°€ì¤‘ì¹˜ ì¡°ì •ì´ ì•„ë‹Œ, **ìœ íš¨ ìƒ˜í”Œ ìˆ˜** ê°œë…ì„ ë„ì…í•œ ì´ë¡ ì  ê·¼ê±°

#### 2. **ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ë¥˜ì— ìµœì í™”**
- í”¼ë¶€ ì§ˆí™˜ ë°ì´í„°ëŠ” **ìì—°ìŠ¤ëŸ½ê²Œ í´ë˜ìŠ¤ ë¶ˆê· í˜•**ì´ ë°œìƒ
- CB LossëŠ” ì´ëŸ¬í•œ **ì˜ë£Œ ë°ì´í„°ì˜ íŠ¹ì„±**ì„ ê°€ì¥ ì˜ ë°˜ì˜

#### 3. **ë°ì´í„° ì¦ê°•ê³¼ì˜ ì‹œë„ˆì§€**
- ë°ì´í„° ì¦ê°•: **í•™ìŠµ ê¸°íšŒ**ë¥¼ ì–‘ì ìœ¼ë¡œ ëŠ˜ë¦¼
- CB Loss: **í•™ìŠµ í’ˆì§ˆ**ì„ ì§ˆì ìœ¼ë¡œ í–¥ìƒ
- ë‘ ê¸°ë²•ì´ **ì„œë¡œ ë‹¤ë¥¸ ë‹¨ê³„**ì—ì„œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì—¬ ì‹œë„ˆì§€ íš¨ê³¼

#### 4. **ê²€ì¦ëœ ì„±ëŠ¥**
- CVPR 2019 ë…¼ë¬¸ì—ì„œ **ì´ë¡ ì  ê·¼ê±°**ì™€ **ì‹¤í—˜ì  ê²€ì¦** ì™„ë£Œ
- ë‹¤ì–‘í•œ ë„ë©”ì¸ì—ì„œ **í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°**ì˜ íš¨ê³¼ ì…ì¦

### 5. CB Loss í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •

#### Î² (Beta) ê°’ì˜ ì—­í• 
- **0.9**: ê°€ë²¼ìš´ ë¶ˆê· í˜• ë³´ì •
- **0.99**: ì¤‘ê°„ ì •ë„ ë¶ˆê· í˜• ë³´ì •  
- **0.999**: ì‹¬ê°í•œ ë¶ˆê· í˜• ë³´ì • (ë³¸ í”„ë¡œì íŠ¸ ê¶Œì¥)
- **0.9999**: ê·¹ì‹¬í•œ ë¶ˆê· í˜• ë³´ì •

#### Î³ (Gamma) ê°’ì˜ ì—­í• 
- **0.5**: Focal Loss íš¨ê³¼ ì•½í•¨
- **1.0**: í‘œì¤€ Focal Loss
- **2.0**: ì–´ë ¤ìš´ ìƒ˜í”Œì— ê°•í•œ ì§‘ì¤‘ (ë³¸ í”„ë¡œì íŠ¸ ê¶Œì¥)
- **3.0**: ë§¤ìš° ê°•í•œ ì§‘ì¤‘

### ê²°ë¡ 
CB LossëŠ” í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œë¥¼ **ì´ë¡ ì ìœ¼ë¡œ ì •í™•í•˜ê²Œ** í•´ê²°í•˜ë©°, í”¼ë¶€ ì´ë¯¸ì§€ ë¶„ë¥˜ì™€ ê°™ì€ ì˜ë£Œ ë°ì´í„°ì˜ íŠ¹ì„±ì— ê°€ì¥ ì í•©í•œ ì†ì‹¤í•¨ìˆ˜ì…ë‹ˆë‹¤. íŠ¹íˆ ë°ì´í„° ì¦ê°•ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ë•Œ **ìµœëŒ€ì˜ ì‹œë„ˆì§€ íš¨ê³¼**ë¥¼ ë°œíœ˜í•©ë‹ˆë‹¤.


## 2-3. í´ë˜ìŠ¤ ë¶ˆê· í˜• ìƒí™©ì—ì„œì˜ í‰ê°€ ì§€í‘œ ì„ íƒ

ì¼ë°˜ì ì¸ ë¶„ë¥˜ ë¬¸ì œì—ì„œëŠ” ì „ì²´ ìƒ˜í”Œ ì¤‘ ì •ë‹µì„ ë§ì¶˜ ë¹„ìœ¨(Val Acc, ì¼ë°˜ ì •í™•ë„)ì´ ì£¼ìš” ì„±ëŠ¥ ì§€í‘œë¡œ ì‚¬ìš©ë¨. ê·¸ëŸ¬ë‚˜ ë³¸ í”„ë¡œì íŠ¸ì™€ ê°™ì´ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ê·¹ì‹¬í•œ ë°ì´í„°ì…‹ì—ì„œëŠ”, Val Accë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ì„ í‰ê°€í•  ê²½ìš° ë‹¤ìˆ˜ í´ë˜ìŠ¤(ìƒ˜í”Œ ìˆ˜ê°€ ë§ì€ í´ë˜ìŠ¤)ì— ëŒ€í•œ ì˜ˆì¸¡ ì„±ëŠ¥ë§Œì´ ë°˜ì˜ë˜ëŠ” ì™œê³¡ì´ ë°œìƒí•¨. ì˜ˆë¥¼ ë“¤ì–´, ì „ì²´ ë°ì´í„°ì˜ 90%ê°€ í´ë˜ìŠ¤ '2'ì— ì†í•œë‹¤ë©´, ëª¨ë¸ì´ ëª¨ë“  ìƒ˜í”Œì„ '2'ë¡œ ì˜ˆì¸¡í•´ë„ Val AccëŠ” 90%ì— ë„ë‹¬í•  ìˆ˜ ìˆìŒ. ì´ ê²½ìš° ì†Œìˆ˜ í´ë˜ìŠ¤ì— ëŒ€í•œ ë¶„ë¥˜ ì„±ëŠ¥ì€ ì „í˜€ ë°˜ì˜ë˜ì§€ ì•ŠìŒ.

ë”°ë¼ì„œ, **Val Balanced Acc(ê· í˜• ì •í™•ë„)**ì™€ **Val Macro F1**ê³¼ ê°™ì€ ì§€í‘œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•¨. Val Balanced AccëŠ” ê° í´ë˜ìŠ¤ë³„ ì •í™•ë„ë¥¼ ë™ì¼í•˜ê²Œ ë°˜ì˜í•˜ì—¬ í‰ê· ì„ ë‚´ë¯€ë¡œ, ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì„±ëŠ¥ ê°œì„ ì´ ì „ì²´ ì§€í‘œì— ì§ì ‘ì ìœ¼ë¡œ ì˜í–¥ì„ ë¯¸ì¹¨. Val Macro F1 ì—­ì‹œ ê° í´ë˜ìŠ¤ì˜ F1 score(ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· )ë¥¼ ì‚°ì¶œí•œ ë’¤ í‰ê· ì„ ë‚´ì–´, ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ê· ë“±í•˜ê²Œ í‰ê°€í•¨. ì´ ë‘ ì§€í‘œê°€ ìƒìŠ¹í•œë‹¤ëŠ” ê²ƒì€, ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ë¿ ì•„ë‹ˆë¼ ì†Œìˆ˜ í´ë˜ìŠ¤ê¹Œì§€ ê³ ë¥´ê²Œ í•™ìŠµí•˜ê³  ìˆìŒì„ ì˜ë¯¸í•¨.

ì‹¤ì œë¡œ, Val Accê°€ ì†Œí­ í•˜ë½í•˜ë”ë¼ë„ Val Balanced Accì™€ Val Macro F1ì´ í¬ê²Œ ì˜¤ë¥´ëŠ” ê²½ìš°, ì´ëŠ” ëª¨ë¸ì´ ê¸°ì¡´ì— ê±°ì˜ êµ¬ë³„í•˜ì§€ ëª»í–ˆë˜ ì†Œìˆ˜ í´ë˜ìŠ¤ë“¤ì„ ë¹ ë¥´ê²Œ í•™ìŠµí•˜ê³  ìˆë‹¤ëŠ” ê°•ë ¥í•œ ì¦ê±°ì„. ë”°ë¼ì„œ ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ëª¨ë¸ ì €ì¥ ê¸°ì¤€ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ì˜ ì£¼ìš” ëª©í‘œ ì§€í‘œë¡œ Val Balanced Accì™€ Val Macro F1ì„ ì±„íƒí•¨.

---

## 3. ê°œë°œ ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë¡œê·¸

### Phase 1: ì´ˆê¸° ëª¨ë¸ ì§„ë‹¨

#### ìƒí™©
- **ëª¨ë¸**: ResNet-50, `Class-Balanced Loss` ì‚¬ìš©
- **ë°ì´í„°**: **ë°ì´í„° ì¦ê°• ë¯¸ì ìš©**. ì›ë³¸ì˜ ë¶ˆê· í˜•í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•¨.

#### ë¬¸ì œì 
1.  **ì‹¬ê°í•œ ê³¼ì í•©**: í•™ìŠµ ì •í™•ë„(Train Acc)ëŠ” 90%ë¥¼ ì´ˆê³¼í•˜ì˜€ìœ¼ë‚˜, ê²€ì¦ ì •í™•ë„(Val Acc)ëŠ” 70%ëŒ€ì—ì„œ ì •ì²´ë¨.
2.  **ì†Œìˆ˜ í´ë˜ìŠ¤ í•™ìŠµ ì‹¤íŒ¨**: ì „ì²´ ì •í™•ë„(`Val Acc`)ì— ë¹„í•´ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ì„ í‰ê· ì ìœ¼ë¡œ ë‚˜íƒ€ë‚´ëŠ” `Val Balanced Acc` ë° `Val Macro F1` ì ìˆ˜ê°€ í˜„ì €íˆ ë‚®ì•˜ìŒ. ì´ëŠ” ëª¨ë¸ì´ ë‹¤ìˆ˜ í´ë˜ìŠ¤ë§Œ ì˜ ë§ì¶”ê³ , ì†Œìˆ˜ í´ë˜ìŠ¤ëŠ” ê±°ì˜ í•™ìŠµí•˜ì§€ ëª»í•˜ê³  ìˆìŒì„ ì˜ë¯¸í•¨.

#### ì´ˆê¸° ë¶„ì„
CB Lossë§Œìœ¼ë¡œëŠ” ê·¹ì‹¬í•œ ë°ì´í„° ë¶ˆê· í˜• ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸°ì— ì—­ë¶€ì¡±ì„. ê·¼ë³¸ì ì¸ ì›ì¸ì€ ëª¨ë¸ì´ ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ íŠ¹ì§•ì„ í•™ìŠµí•  **ê¸°íšŒ ìì²´ê°€ ë¶€ì¡±**í•œ ê²ƒì´ë¯€ë¡œ, ë°ì´í„° ì¦ê°•ì„ í†µí•œ **ì˜¤ë²„ìƒ˜í”Œë§(Oversampling)**ì´ ì‹œê¸‰í•˜ë‹¤ê³  íŒë‹¨í•¨.

---

### Phase 2: ë°ì´í„° ì¦ê°•ê³¼ Class-Balanced Lossì˜ ì‹œë„ˆì§€ íš¨ê³¼

#### í•µì‹¬ ê°€ì„¤ ì„¤ì •
í”„ë¡œì íŠ¸ì˜ ê°€ì¥ ì¤‘ìš”í•œ ë…¼ì˜.
> "ë°ì´í„° ì¦ê°•(ì˜¤ë²„ìƒ˜í”Œë§)ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ë¶„í¬ë¥¼ ê· ì¼í•˜ê²Œ ë§ì¶˜ë‹¤ë©´, í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ì „ì œë¡œ í•˜ëŠ” Class-Balanced LossëŠ” ì˜ë¯¸ê°€ ì—†ì–´ì§€ëŠ” ê²ƒì¸ê°€?"

#### ê²°ë¡ : ìƒí˜¸ ë°°íƒ€ì ì´ ì•„ë‹Œ, ê°•ë ¥í•œ ì‹œë„ˆì§€ ê´€ê³„ì„
ë‘ ê¸°ë²•ì€ ì„œë¡œ ë‹¤ë¥¸ ë‹¨ê³„ì—ì„œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ë•Œë¬¸ì— í•¨ê»˜ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ì¥ í° íš¨ê³¼ë¥¼ ëƒ„.

- **ë°ì´í„° ì¦ê°• (Oversampling)**: **Data-Level ì ‘ê·¼ë²•**ì„.
  - ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë™ì•ˆ ê° í´ë˜ìŠ¤ë¥¼ ë§Œë‚˜ê²Œ ë˜ëŠ” **ë¹ˆë„**ë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ê· ë“±í•˜ê²Œ ë§ì¶¤.
  - ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ íŠ¹ì§•ì„ í•™ìŠµí•  **ê¸°íšŒ**ë¥¼ ì–‘ì ìœ¼ë¡œ ëŠ˜ë ¤ì£¼ëŠ” ì—­í• ì„ í•¨.

- **Class-Balanced Loss**: **Loss-Level ì ‘ê·¼ë²•**ì„.
  - ì˜ˆì¸¡ì´ í‹€ë ¸ì„ ë•Œ ë°œìƒí•˜ëŠ” ì†ì‹¤(Loss)ì˜ **íŒ¨ë„í‹° ê°•ë„**ë¥¼ ì¡°ì ˆí•¨.
  - ë°ì´í„°ì˜ **ë³¸ì§ˆì ì¸ í¬ì†Œì„±(inherent rarity)**ì„ ê¸°ë°˜ìœ¼ë¡œ, ë°°ìš°ê¸° ë” ì–´ë ¤ìš´ ì†Œìˆ˜ í´ë˜ìŠ¤ë¥¼ í‹€ë ¸ì„ ë•Œ ë” í° íŒ¨ë„í‹°ë¥¼ ë¶€ì—¬í•¨. (Class-Balanced Loss[1])

---

### Phase 3: ì½”ë“œ ê¸°ë°˜ ì¦ëª… ë° í•™ìˆ ì  ê·¼ê±°

ìœ„ ì‹œë„ˆì§€ íš¨ê³¼ê°€ ë‹¨ìˆœí•œ ì¶”ë¡ ì´ ì•„ë‹Œ, ì½”ë“œì˜ ì‹¤ì œ ë™ì‘ ë°©ì‹ê³¼ í•™ìˆ ì  ì›ë¦¬ì— ê¸°ë°˜í•˜ê³  ìˆìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

#### ì½”ë“œ ì‹¤í–‰ ìˆœì„œë¥¼ í†µí•œ ì¦ëª…
í”„ë¡œì íŠ¸ì˜ `main.py`ëŠ” ë‘ ê¸°ë²•ì˜ ì‹œë„ˆì§€ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ë§¤ìš° ì´ìƒì ìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

1.  **1ë‹¨ê³„: ì›ë³¸ ë¶ˆê· í˜• ì •ë³´ ìº¡ì²˜**
    - ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ê¸° **ì „**, ì›ë³¸ í•™ìŠµ ë°ì´í„°ì…‹ì˜ ë¶ˆê· í˜•í•œ í´ë˜ìŠ¤ ë¶„í¬(ì˜ˆ: `{'2': 5443, '5': 101, ...}`)ë¥¼ `train_samples_per_cls` ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
2.  **2ë‹¨ê³„: CB Loss ì´ˆê¸°í™”**
    - `train_samples_per_cls` ë³€ìˆ˜ê°€ `Model` í´ë˜ìŠ¤ë¡œ ì „ë‹¬ë˜ì–´ `CB_loss`ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. ì´ ì‹œì ì—ì„œ `CB_loss`ëŠ” ê° í´ë˜ìŠ¤ì˜ **ì›ë³¸ ìƒ˜í”Œ ìˆ˜**ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê³ ìœ ì˜ ë³´ìƒ ê°€ì¤‘ì¹˜ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ê³„ì‚°í•˜ê³  "ê¸°ì–µ"í•©ë‹ˆë‹¤.
3.  **3ë‹¨ê³„: ë°ì´í„°ì…‹ êµì²´ ë° í•™ìŠµ**
    - ê·¸ í›„, `train_dataset`ì´ `AugmentedSkinDataset`ìœ¼ë¡œ êµì²´ë˜ì–´ `DataLoader`ëŠ” ëª¨ë¸ì— ê· í˜• ì¡íŒ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•©ë‹ˆë‹¤.

ê²°ê³¼ì ìœ¼ë¡œ, ëª¨ë¸ì€ ê· ë“±í•œ í•™ìŠµ ê¸°íšŒë¥¼ ì–»ëŠ” ë™ì‹œì—, ì†ì‹¤ í•¨ìˆ˜ëŠ” ì›ë³¸ ë°ì´í„°ì˜ í¬ì†Œì„±ì„ ê¸°ì–µí•˜ê³  íŒ¨ë„í‹°ë¥¼ ì°¨ë“±ì ìœ¼ë¡œ ë¶€ê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### í•™ìˆ ì  ê·¼ê±°
ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì€ ë‹¤ìŒì˜ ë…¼ë¬¸ë“¤ì—ì„œ ì œì•ˆëœ ì›ë¦¬ì™€ ì¼ì¹˜í•©ë‹ˆë‹¤.

- **Class-Balanced Loss**:
  > Cui, Y., et al. (2019). "Class-Balanced Loss Based on Effective Number of Samples". *CVPR*.[1]
  - **ë‚´ìš©**: `beta` ê°’ì„ ì´ìš©í•´ 'ìœ íš¨ ìƒ˜í”Œ ìˆ˜'ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†Œìˆ˜ í´ë˜ìŠ¤ì— ê°•ë ¥í•œ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ë˜í•œ ì œì•ˆëœ ì†ì‹¤ í•¨ìˆ˜ê°€ ë°ì´í„° ìƒ˜í”Œë§ ì „ëµê³¼ **ìƒí˜¸ ë³´ì™„ì **ì´ë¼ê³  ëª…ì‹œí•©ë‹ˆë‹¤.

- **Focal Loss**:
  > Lin, T. Y., et al. (2017). "Focal Loss for Dense Object Detection". *ICCV*.[2]
  - **ë‚´ìš©**: `gamma` ê°’ì„ ì´ìš©í•´ ëª¨ë¸ì´ ì‰½ê²Œ ë§ì¶”ëŠ” ìƒ˜í”Œì˜ ì†ì‹¤ì„ ì¤„ì—¬, ì–´ë µê³  ì• ë§¤í•œ ìƒ˜í”Œì— ì§‘ì¤‘í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤. (ë³¸ í”„ë¡œì íŠ¸ì˜ CB LossëŠ” Focal Loss ë©”ì»¤ë‹ˆì¦˜ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.)

---

## 4. ìµœì¢… ì‹¤í–‰ ê³„íš ë° ê¶Œì¥ ì‚¬í•­

### 1. ë°ì´í„° ì¦ê°• í™œì„±í™”
`main.py` ì‹¤í–‰ ì‹œ `--use_augmentation` í”Œë˜ê·¸ë¥¼ **ë°˜ë“œì‹œ ì¶”ê°€**í•˜ì—¬ `AugmentedSkinDataset`ì„ í™œì„±í™”í•¨.

### 2. Class-Balanced Loss ìœ ì§€
`--train_loss cb` ì˜µì…˜ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì¦ê°•ê³¼ì˜ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í•¨.

### 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
- **`beta` (CB Loss)**: ì›ë³¸ ë°ì´í„°ì˜ ê·¹ì‹¬í•œ ë¶ˆê· í˜•ì„ ë³´ìƒí•˜ê¸° ìœ„í•´ `0.999` ë˜ëŠ” `0.9999`ì™€ ê°™ì€ ë†’ì€ ê°’ì„ ìœ ì§€í•¨.
- **`gamma` (CB Loss)**: `2.0`ì„ í‘œì¤€ ì‹œì‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , `wandb.sweeps`ë¥¼ í†µí•´ ìµœì  ê°’ì„ íƒìƒ‰í•¨.

### 4. ëª¨ë¸ ì €ì¥ ê¸°ì¤€ ë³€ê²½
ê³¼ì í•©ëœ ëª¨ë¸ì´ ì•„ë‹Œ, ì†Œìˆ˜ í´ë˜ìŠ¤ê¹Œì§€ ì˜ ì¼ë°˜í™”ëœ ìµœìƒì˜ ëª¨ë¸ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ì €ì¥ ê¸°ì¤€ì„ ë³€ê²½í•¨.

**`main.py` ìˆ˜ì •**
```python
# ê¸°ì¡´ ì½”ë“œ
# if val_acc > best_acc:
#     best_acc = val_acc
#     ...

# ìˆ˜ì • ì½”ë“œ
best_metric = 0 # best_acc -> best_metric ìœ¼ë¡œ ë³€ìˆ˜ëª… ë³€ê²½
if val_bal_acc > best_metric: # val_acc ëŒ€ì‹  val_bal_acc ë˜ëŠ” val_macro_f1 ì‚¬ìš©
    best_metric = val_bal_acc
    print(f"*** New Best Model Found (Val Balanced Acc: {best_metric:.4f}) at Epoch {epoch} ***")
    # model.save_checkpoint í˜¸ì¶œ
```

### 5. `wandb.sweeps`ë¥¼ ì´ìš©í•œ ìµœì¢… ìµœì í™”
ìœ„ì˜ ë³€ê²½ ì‚¬í•­ì„ ëª¨ë‘ ì ìš©í•œ í›„, `wandb.sweeps`ë¥¼ ì‹¤í–‰í•˜ì—¬ ìƒˆë¡œìš´ í•™ìŠµ í™˜ê²½ì— ë§ëŠ” ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©(learning rate, dropout, gamma ë“±)ì„ íƒìƒ‰í•¨.

**`sweep.yaml` ì„¤ì • ì˜ˆì‹œ:**
```yaml
method: bayes
metric:
  name: val_balanced_acc
  goal: maximize
parameters:
  learning_rate:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.001
  gamma:
    values: [0.5, 1.0, 2.0, 3.0]
  dropout_prob:
    values: [0.2, 0.3, 0.4, 0.5]
  # ... ê¸°íƒ€ íŒŒë¼ë¯¸í„°
```

---

## 5. ì½”ë“œ êµ¬ì¡° ë° ì „ì²´ ë™ì‘ ê³¼ì • (ìš”ì•½)

- `dataset_double.py`: ë°ì´í„°ì…‹ ë¡œë”©, ì¦ê°•, í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ë¶„ì„ì„ ë‹´ë‹¹í•¨.
- `main.py`: ì‹¤í—˜ íŒŒë¼ë¯¸í„° ê´€ë¦¬, ë°ì´í„° ë¶„í• , ì¦ê°•/ë¶ˆê· í˜• ë³´ì •, í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸, wandb resume ì§€ì›ì„ ë‹´ë‹¹í•¨.
- `model.py`: ResNet50 ê¸°ë°˜ ë¶„ë¥˜ê¸°, ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜, ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•¨.
- `utils.py`: FocalLoss, CB_loss, LabelSmoothing ë“± ì†ì‹¤ í•¨ìˆ˜, ë°ì´í„° ë¶„ì„/ì¦ê°• ìœ í‹¸ì„ ë‹´ë‹¹í•¨.
- `resnet_custom.py`: stride=1 ë“± ì»¤ìŠ¤í…€ ResNet50 êµ¬í˜„ì„ ë‹´ë‹¹í•¨.

### ì „ì²´ ë™ì‘ ìˆœì„œ
1. main.py ì‹¤í–‰ â†’ argparseë¡œ ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì…ë ¥
2. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„ì„ (dataset_double.py)
3. ì¦ê°•(transform) ì ìš© ì—¬ë¶€ ê²°ì •
4. train/val/test ë¶„í• 
5. ëª¨ë¸(Model) ìƒì„± ë° wandb, optimizer, scheduler ë“± ì´ˆê¸°í™”
6. (resume ì‹œ) ì²´í¬í¬ì¸íŠ¸ ë° wandb run idë¡œ ì´ì–´ì„œ í•™ìŠµ
7. í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë£¨í”„ ì§„í–‰, wandbì— ì‹¤í—˜ ê²°ê³¼ ê¸°ë¡
8. best model ë° ì‹¤í—˜ ê²°ê³¼ ì €ì¥

---

## 6. ì‚¬ìš©ë²• ì˜ˆì‹œ

### 1. ìƒˆ ì‹¤í—˜ ì‹œì‘
```bash
python main.py --data_dirs ./data --epochs 50 --use_augmentation --wandb_name "exp1"
```

### 2. ì´ì–´ì„œ í•™ìŠµ ë° wandb ê·¸ë˜í”„ ì´ì–´ ê·¸ë¦¬ê¸°
1. wandb ëŒ€ì‹œë³´ë“œì—ì„œ ì´ì–´ì„œ ê·¸ë¦¬ê³  ì‹¶ì€ runì˜ idë¥¼ ë³µì‚¬ (ì˜ˆ: 2x3y4z5w)
2. ì•„ë˜ì²˜ëŸ¼ ì‹¤í–‰í•¨
```bash
python main.py --resume checkpoints_YYYYMMDD_HHMMSS/best_model.pth --wandb_id 2x3y4z5w --wandb_resume allow
```

---

## 7. ê¸°íƒ€ ì°¸ê³ ì‚¬í•­
- ë°ì´í„° ì¦ê°•ì€ transform ì¸ìì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ì ìš©ë¨
- CB Loss, Focal Loss ë“± ë‹¤ì–‘í•œ ì†ì‹¤ í•¨ìˆ˜ ì‹¤í—˜ ê°€ëŠ¥í•¨
- ì‹¤í—˜ ì¬í˜„ì„±, wandb ì‹¤í—˜ ê´€ë¦¬, ì²´í¬í¬ì¸íŠ¸ resume ë“± ì‹¤ì „ ì—°êµ¬ì— ìµœì í™”ë˜ì–´ ìˆìŒ

## ì°¸ê³ ë¬¸í—Œ

[1] Cui, Y., Jia, M., Lin, T. Y., Song, Y., & Belongie, S. (2019). Class-Balanced Loss Based on Effective Number of Samples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 9268-9277.

[2] Lin, T. Y., Goyal, P., Girshick, R., He, K., & DollÃ¡r, P. (2017). Focal Loss for Dense Object Detection. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 2980-2988.